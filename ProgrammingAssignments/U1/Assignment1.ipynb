{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Face-Classification Two-Ways\n",
    "\n",
    "In this assignment you will implement a face classifier and train it using two different approaches:\n",
    "* Regression using Gradient Descent\n",
    "* Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before running the code please make sure that you have all the necessary packages installed. Make sure that you have installed \"scikit-image\" package. \n",
    "First import the required packages and do some setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys \n",
    "sys.path.append('./assignment1_solutions')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from assignment1_solutions import hog_features, tanh, gda, cost_function, gradient_function, tanh_GD, predict_function\n",
    "\n",
    "# Set default parameters for plots\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the data set. It consists of 19'832 grayscale images of size 24 x 24. Each image has a corresponding label which we set to -1 for non-face and 1 for face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = loadmat('faces.mat')\n",
    "labels = np.squeeze(data['Labels'])\n",
    "data = data['Data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the dataset into two subsets: One for training and one for testing. This approach is called cross-validation and is standard practice in Machine Learning.\n",
    "The classifier will be learnt only on the data in the training set! The test set then gives you an estimate of how well the classifier will perform on new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3)\n",
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the images are stored as vectors now. Let's visualize some examples to check that the data is fine. We of course have to reshape the images first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "samples_per_class = 10\n",
    "classes = [-1, 1]\n",
    "train_imgs = np.reshape(X_train, [-1, 24, 24], order='F')\n",
    "\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(np.equal(y_train, cls))\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = y * samples_per_class + i + 1\n",
    "        plt.subplot(len(classes), samples_per_class, plt_idx)\n",
    "        plt.imshow(train_imgs[idx])\n",
    "        plt.axis('off')\n",
    "        plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add the intercept term by concatenating a vector of ones to the train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept to X and normalize to range [0, 1]\n",
    "X_train = np.concatenate((np.ones((num_train, 1)), X_train/255.), axis=1)\n",
    "X_test = np.concatenate((np.ones((num_test, 1)), X_test/255.), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Tanh [5 Points]\n",
    "\n",
    "**TODO**: Implement the tanh function in ***assignment1/tanh.py*** according to the specifications. $tanh(x) = \\frac{e^{2x}-1}{e^{2x}+1}$<br>\n",
    "**NOTE**: The function should work with inputs of arbitrary shape!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your Tanh\n",
    "z_test = np.arange(-5, 5, 0.01)\n",
    "g_test = tanh(z_test)\n",
    "plt.plot(z_test, g_test)\n",
    "plt.title('Tanh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Cost Function [10 Points]\n",
    "\n",
    "**TODO**: Implement the cost function for Regression in ***assignment1/cost_function.py*** according to specs. $\\mathcal{L}(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}(tanh(\\theta^{T}x_{i})-y_{i})^{2}$<br>\n",
    "What value of the cost do you expect with a parameter vector *theta* of all zeros? Check your implementation for this!\n",
    "\n",
    "**Hint**: No for-loops are required! Use np.sum and np.dot instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your cost-function\n",
    "theta_0 = np.zeros(X_train.shape[1])\n",
    "l_0 = cost_function(theta_0, X_train, y_train)\n",
    "print('Cost with initial theta: ', l_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: The Gradient [10 Points]\n",
    "\n",
    "**TODO**: Compute and implement the gradient of the cost function in ***assignment1/gradient_function.py***. \n",
    "\n",
    "**NOTE**: Your implementation should work with a single example x (i.e., a vector) or multiple examples X (i.e., a matrix).\n",
    "\n",
    "Consider again what value you would expect with *theta* equal to zero and test your implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your implementation\n",
    "x_test = np.ones([2, 10])\n",
    "theta_0 = np.zeros(10)\n",
    "grad_0 = gradient_function(theta_0, x_test, 1.0)\n",
    "print(grad_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: The Learning Algorithmms\n",
    "\n",
    "This is the main part of the assignment. Correctness of the implementation is required to get the points (work on speed later). \n",
    "\n",
    "## a) Regression with GD [15 Points]\n",
    "\n",
    "**TODO**: Implement the function in ***assignment1/tanh_GD.py*** according to specs.\n",
    "\n",
    "## b) Gaussian Discriminant Analysis [15 Points]\n",
    "\n",
    "**TODO**: Implement the function in ***assignment1/gda.py*** according to specs.\n",
    "\n",
    "\n",
    "\n",
    "***Hint***: No additional for-loops are required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'gd'\n",
    "\n",
    "# We'll meausure the execution time\n",
    "start = time.time()\n",
    "\n",
    "if method is 'gd':\n",
    "    theta, losses = tanh_GD(X_train, y_train)\n",
    "elif method is 'gda':\n",
    "    theta, losses = gda(X_train, y_train)\n",
    "else:\n",
    "    raise ValueError('Method not recognised!')\n",
    "\n",
    "exec_time = time.time()-start\n",
    "print('Total exection time: {}s'.format(exec_time))\n",
    "\n",
    "if losses:\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Cost')\n",
    "    plt.show()\n",
    "\n",
    "# We can have a look at what theta has learned to recognise as \"face\"\n",
    "plt.imshow(np.reshape(theta[1:], [24, 24], order='F'))\n",
    "plt.title('Learned theta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Testing the Classifier [10 Points]\n",
    "\n",
    "**TODO**: Implement ***assignment1/predict_function.py*** according to specs. \n",
    "\n",
    "Test your implementation with the intial all zero theta as well! Does it match your expectation?\n",
    "\n",
    "***Hint***: All the methods should score above 90% on both the test and train set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the final classifier\n",
    "pred_test, accuracy_test = predict_function(theta, X_test, y_test)\n",
    "pred_train, accuracy_train = predict_function(theta, X_train, y_train)\n",
    "print('Test accuracy: {}'.format(accuracy_test))\n",
    "print('Training accuracy: {}'.format(accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Preprocessing [15 Points]\n",
    "\n",
    "**TODO**: Implement ***assignment1/features.py*** according to specs.\n",
    "\n",
    "Up to this point we trained our classifiers dirrectly on image pixel intensities. \n",
    "In this exercise you should extract HOG features from the training and test images and train on the extracted features. Make sure that you reshape the extracted HOG features before you start training. \n",
    "For HOG feature extractor you can have a look at http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py. For documentation please have a look at http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog. Make sure that you tune the parameters of the HOG feature extractor to get the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG feature extraction can take several minutes at most on your PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features\n",
    "X_train_hog = hog_features(X_train)\n",
    "X_test_hog = hog_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train on HOG features and measure the testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll meausure the execution time\n",
    "methods = ['gd','gda']\n",
    "\n",
    "for method in methods:\n",
    "    print('Training ' + method)\n",
    "    # We'll meausure the execution time\n",
    "    start = time.time()\n",
    "\n",
    "    if method is 'gd':\n",
    "        theta, losses = tanh_GD(X_train_hog, y_train)\n",
    "    elif method is 'gda':\n",
    "        theta, losses = gda(X_train_hog, y_train)\n",
    "    else:\n",
    "        raise ValueError('Method not recognised!')\n",
    "\n",
    "    exec_time = time.time()-start\n",
    "    print('Total exection time for ' + method + ': {}s'.format(exec_time))\n",
    "\n",
    "    if losses:\n",
    "        plt.plot(losses)\n",
    "        plt.title('Training Cost for ' + method)\n",
    "        plt.show()\n",
    "\n",
    "    pred_test, accuracy_test = predict_function(theta, X_test_hog, y_test)\n",
    "    pred_train, accuracy_train = predict_function(theta, X_train_hog, y_train)\n",
    "    print(str('Test accuracy for ' + method + ': '+'{}').format(accuracy_test))\n",
    "    print(str('Training accuracy for ' + method + ': '+'{}\\n\\n\\n').format(accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Discussion [20 Points]\n",
    "\n",
    "Answer the following questions and justify your answers:\n",
    "\n",
    "* Based on your results, which classifier do you prefer and why?\n",
    "\n",
    "\t***Your Answer:***\n",
    "    \n",
    "* Regression vs. GDA: Give advantages and disadvantages of both approaches. How would you expect the results to change if more or less data were used during training?\n",
    "\n",
    "\t***Your Answer:***\n",
    "    \n",
    "* Pixel Values VS HOG Features: Based on your results, did HOG features improve the performence of the classifier?\n",
    "\n",
    "   ***Your Answer:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Make it fast! [10 Points]\n",
    "\n",
    "Optimise your implementations by making good use of Numpy. If your implementation of one of the methods is within a factor of two of the reference implementation you'll earn 5 additional points (a total of 15 points possible for the two methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
